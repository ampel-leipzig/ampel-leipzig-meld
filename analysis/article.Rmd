---
# R markdown template taken from
# Dan Holmes <dtholmes@mail.ubc.ca>
# https://labrtorian.com/2019/08/26/rmarkdown-template-that-manages-academic-affiliations/
title: "A Model to Predict Survival in Patients with End-Stage Liver Disease"
subtitle: >
    Comparision against MELD, MELD-Na, MELD-Plus7.
abstract: >
  **Background**:
      TODO

  **Methods**:
      TODO

  **Results**:
      TODO

  **Conclusion**:
      TODO

author:
    - Sebastian Gibb:
        email: mail@sebastiangibb.de
        institute: [ILM, KAINS]
        correspondence: true
    - Thorsten Kaiser:
        email: thorsten.kaiser@medizin.uni-leipzig.de
        institute: ILM
        correspondence: false
institute:
    - ILM: Institute of Laboratory Medicine, Clinical Chemistry and Molecular Diagnostics, University Hospital Leipzig, Paul-List-Str. 13-15, D-04103 Leipzig, Germany.
    - KAINS: Anesthesiology and Intensive Care Medicine, University Hospital Greifswald, Ferdinand-Sauerbruch-Stra√üe, D-17475 Greifswald, Germany.
date: "`r Sys.Date()`"
bibliography:
  - "`r rprojroot::find_rstudio_root_file('analysis', 'bibliography', 'bibliography.bib')`"
  - "`r rprojroot::find_rstudio_root_file('analysis', 'bibliography', 'rpackages', 'article.bib')`"
output:
  bookdown::html_document2:
    pandoc_args: # pandoc_args doesn't support r evaluation
      - --lua-filter=pandoc/lua-filters/scholarly-metadata.lua
      - --lua-filter=pandoc/lua-filters/author-info-blocks.lua
  bookdown::word_document2:
    pandoc_args: # pandoc_args doesn't support r evaluation
      - --lua-filter=pandoc/lua-filters/scholarly-metadata.lua
      - --lua-filter=pandoc/lua-filters/author-info-blocks.lua
---

```{r knitr_setup, include=FALSE}
knitr::write_bib(
    c(
        "base",
        "targets", "workflowr",
        "gtsummary",
        "mlr3", "mlr3proba", "zlog",
        "survival", "glmnet", "penalized", "ranger", "randomForestSRC",
        "xgboost", "survivalsvm", "survivalmodels", "timeROC"
    ),
    file = rprojroot::find_rstudio_root_file(
        "analysis", "bibliography", "rpackages", "article.bib"
    )
)
```

```{r article_setup, include=FALSE}
library("targets")
library("ggplot2")
library("mlr3viz")
library("viridis")
library("ameld")

tar_load(bmrk_results)
tar_load(crossval)
tar_load(tuner)

tar_load(raw_data)
tar_load(labelled_meld_data)

tar_load(tbl1)
tar_load(tbl_observed_vs_expected_mortality)

tar_load(ameldcfg)
```

# Introduction

Liver cirrhosis is the terminal result of fibrotic remodeling
of liver tissue due to chronic damage. An organ failure is often
irreversible and the only available therapy is liver transplantation.
However, the shortage in grafts for transplantation from deceased donors
requires risk stratification and precise allocation rules.
The allocation of liver transplantation in most countries is based on
disease severity determined by the model of end-stage liver disease (MELD)
[@malinchoc2000; @wiesner2003; @optn_policies2021].
The MELD score estimates the patients' 3-month mortality risk based on
laboratory results, namely bilirubin, creatinine and international normalized
ratio (INR). In general the MELD score is extended by the sodium level
(MELD-Na score) as this was found to be an important additional risk factor in
liver cirrhosis [@kim2008; @optn_policies2021].
The MELD was initially developed for predicting the survival of patients
undergoing transjugular intrahepatic portosystemic shunts.
Afterwards it was revalidated for predicting mortality risk in patients awaiting
a liver transplantation.
Although the MELD score should be an objective allocation score especially the
creatinine and INR are highly dependent on the utilized laboratory methods
[@trotter2004; @cholongitas2007]. Patients with identical disease state could
have very different MELD scores and thus get different priority on the liver
transplantation waiting list.
Furthermore often, e.g. for acute-on-chronic liver failure, the MELD score
underestimates the mortality risk [@hernaez2020].

There have been some attempts to use the data extracted from more than 300.000
electronic medical records from two hospitals in the United States to improve
the MELD score [@kartoun2017]. The derived MELD-Plus7 and MELD-Plus9 risk score
add albumin, white blood cell count, total cholesterol, age and length of
stay to the MELD-Na variables. Despite its published prediction improvement the
MELD-Plus scores are not used for transplant allocation yet.

As depicted by MELD-Plus risk scores better predictive scores often need more
variables and are more complicated. To reduce the risk of overlooking or
incorrectly calculating and interpreting the results,
clinical decision support systems may be used and could improve patient safety.
The research project on digital laboratory medicine (AMPEL) develops a
clinical decision support system based on laboratory diagnostics that should
support clinical practitioners in interpreting the laboratory results and taking
the necessary medical interventions [@eckelt2020].

This study aims to find clinical and laboratory values that improve the risk
stratification for liver transplantation over classical MELD, MELD-Na and
MELD-Plus scores and could be implemented as part of the AMPEL clinical decision
support system.

# Material and methods

## Study population

```{r excluded, include = FALSE}
n_excluded <- attr(raw_data, "excluded")
n_analysed <- nrow(raw_data)
n_total <- sum(n_analysed, n_excluded)

cn_labs <- grep("_[CESQ]$", colnames(raw_data), value = TRUE)
```

In a retrospective cohort study we followed `r n_total` consecutive
patients, who were recruited during the evaluation process for
liver transplantation at the University Hospital of Leipzig from
`r paste(format(attr(raw_data, "period"), "%B %Y"), collapse = " to ")`.
For each patient we recorded `r ncol(raw_data)` variables.
Among them are age, sex, etiology of liver disease, complications as listed in
Table \@ref(tab:tbl1) and `r length(cn_labs)` laboratory measurements.

```{r flowchart, results = "asis", eval = knitr::is_html_output(), echo = FALSE, fig.width = 5, fig.height = 5, fig.cap = "Flowchart Inclusion/Exclusion."}
graph <- "
digraph flowchart {
    graph [splines = false];

    // invisible nodes
    node [shape = point, width = 0, height = 0];
    iAR [style = 'invis'];

    // visible nodes
    node [shape = box];
    A [label = '@@1'];
    E [label = '@@3'];
    R [label = '@@2'];

    // edge statements
    A -> iAR [arrowhead = none];
    {rank = same; iAR -> E [minlen = 5]};
    iAR -> R;
}

[1]: paste0('Total Records\\n(n = ', n_total, ')')
[2]: paste0('Analysed Records\\n(n = ', n_analysed, ')')
[3]: str_excluded
"
str_excluded <- paste0(
    'Excluded (n = ', sum(n_excluded), ')\\\\l',
    paste0(
        '- ',
        paste(
            c(
                'Younger than 18 years:',
                'Liver Transplantation before visit:',
                'Follow-up missing/invalid:'
            ),
            n_excluded
        ),
        collapse = '\\\\l'
    ),
    '\\\\l'
)

DiagrammeR::grViz(graph)
```

We excluded `r sum(n_excluded)` patients from our analysis
(Figure \@ref(fig:flowchart)).
`r if (n_excluded["Children"] == 1) "One was" else paste(n_excluded["Children"], "were")` younger than 18 years.
`r n_excluded["LiverTransplantation"]` had a liver transplantation before and
in `r n_excluded["LostFollowUp"]` cases the follow up data were missing or
invalid.

The Ethics Committee at the Leipzig University Faculty of
Medicine approved the retrospective usage of the data for our study
(reference number: 039/14ff).

## MELD scores

MELD and MELD-Na were calculated as described in
@optn_policies2021 using the following formulas:
$MELD = 10 * (0.957 \ln(creatinine [mg/dl]) + 0.378 \ln(bilirubin [mg/dl]) + 1.120 * \ln(INR) + 0.643)$,
Creatinine, bilirubin and INR values lower than 1.0 mg/dl were set to 1.0 mg/dl.
The maximum allowed creatinine was 4.0 mg/dl. If patients received dialysis,
creatinine was set to 4.0 mg/dl.
For MELD-Na MELD was calculated as above and recalculated if greater than 11 using:
$MELD\text{-}Na = MELD_i + 1.32 * (137 - Na [mmol/l]) - (0.033 * MELD_i * (137 - Na [mmol/l]))$

Serum sodium values lower than 125 mmol/l or higher than 137 mmol/l were set
to 125 mmol/l and 137 mmol/l, respectively.

The MELD-Plus7 risk score was calculated as described in @kartoun2017:
$$
\begin{aligned}
L = 8.53499496 &+ \\
    2.59679650 &* \log_{10}(1 + creatinine [mg/dl]) + \\
    2.06503238 &* \log_{10}(1 + bilirubin [mg/dl]) + \\
    2.99724802 &* \log_{10}(1 + INR) - \\
    6.47834101 &* \log_{10}(1 + sodium [mmol/l]) - \\
    6.34990436 &* \log_{10}(1 + albumin [g/l]) + \\
    1.92811726 &* \log_{10}(1 + wbc [th/cumm]) + \\
    0.04070442 &* age [years]
\end{aligned}
$$

$$MELD\text{-}Plus = \frac{\exp(L)}{1 + \exp(L)}$$

The MELD-Plus9 score was ignored because the length of stay information was not
available for our cohort and the model itself wasn't superior to MELD-Plus7 in
its original publication [@kartoun2017].

## Data processing and machine learning

```{r ml, include = FALSE}
n_lrns <- sum(!grepl("^scale..*", bmrk_results$learners$learner_id))
```

All data processing, statistical and machine learning analyses were performed
using R version
`r paste0(sessionInfo()$R.version[c("major", "minor")], collapse = ".")`
[@R-base].
Prior to the analyses all laboratory values were *zlog* transformed
as described in @hoffmann2017 and implemented in @R-zlog.

$$
z = (\log(x) - \frac{\log(LL) + \log(UL)}{2}) * \frac{3.92}{\log(UL) - \log(LL)}
$$

Where $LL$ and $UL$ are the lower and upper reference limit of
the corresponding laboratory diagnostic, respectively.
Missing laboratory measurements were replaced with a *zlog* value of zero.
In similar manner if information about complications or
comorbidities were missing we treat them as not present.

We compared `r n_lrns` different statistical and machine learning
algorithms using the *mlr3* framework
[@mlr3; @R-mlr3; @mlr3proba2021; @R-mlr3proba].
The used algorithms are designed for analysis of survival data:
Cox proportional hazards regression model
[@cox1972; @survival-book; @R-survival],
penalized regressions,
namely two different implementations of the
lasso (least absolute shrinkage and selection operator) regression
[@tibshirani1997; @glmnet2011; @R-glmnet; @penalized2010; @R-penalized],
tow different implementations of the
ridge regression [@glmnet2011; @R-glmnet; @penalized2010; @R-penalized], and
the elastic net regression [@glmnet2011; @R-glmnet],
two different random forest implementations
[@ranger2017; @R-ranger; @randomForestSRC2008; @R-randomForestSRC],
extreme gradient boosting [@chen2016; @R-xgboost],
two different support vector machines [@vanbelle2011; @R-survivalsvm]
and two neural networks [@katzman2018; @kvamme2019; @R-survivalmodels].

To choose the best model we used nested resampling to avoid feature- and
model-selection-bias.
Therefore, we applied a `r crossval$inner$param_set$values$folds`-fold inner
and a `r crossval$outer$param_set$values$folds`-fold outer cross-validation
that was repeated `r crossval$outer$param_set$values$repeats` times.
We searched the hyperparameter space using a grid search with a resolution of
`r tuner$param_set$get_values()$resolution`.
Subsequently we selected the model with the
highest median concordance index [@harrell1982]. If multiple models were
comparable we chose the simpler (more penalized) one.

After selecting the final model we trained and validated it as described in
@harrell1996.
Briefly we developed our model and predicted survival at `r ameldcfg$times` days.
The predictions were grouped into equal sized intervals so that there
are `r ameldcfg$m` patients in each interval.
For each group the mean survival probability and the difference to the
Kaplan-Meier estimate was calculated.
The same procedure was repeated for `r ameldcfg$nboot` bootstrap samples.
Subsequently the differences between predicted survival and Kaplan-Meier
estimates of the bootstrap samples were averaged and added to the original
model difference to obtain a bias-corrected estimated between predicted and
observed survival.

The final model was compared against the MELD, MELD-Na and MELD-Plus7 score
using the area under the time-dependent ROC curve (AUC)
based on the nonparametric inverse probability of censoring weighting estimator
(IPCW) [@blanche2013, @R-timeROC].

Summary tables were built using the *gtsummary* package
[@gtsummary; @R-gtsummary].

# Results

## Baseline characteristics

```{r tbl1, results = "asis", echo = FALSE, message = FALSE, warning = FALSE}
library("gtsummary")
theme_gtsummary_journal(journal = "jama")
theme_gtsummary_compact()
tbl1
```

```{r tbl1_helper_func, echo = FALSE}
.tbl1 <- function(variable, column = "Overall", ...) {
    id <- gtsummary::inline_text(
        tbl1, variable = all_of(variable), column = "tbl_id1"
    )
    if (column == "Overall")
        column <- "stat_0"
    gtsummary::inline_text(
        tbl1$tbls[[id]],
        variable = all_of(variable), column = all_of(column), ...
    )
}
```

In this study we analysed a cohort of `r n_analysed` patients evaluated for
liver transplantation (Tab. \@ref(tab:tbl1)).
`r sprintf("%i (%s)", sum(raw_data$Sex == "male"), gtsummary::style_percent(mean(raw_data$Sex == "male"), symbol = TRUE))`
of them were men.
The median (IQR) follow-up times was `r .tbl1("DaysAtRisk")` days.
Within the follow-up time `r .tbl1("LTx")` patients received a liver transplant
and were censored for the analysis beyond this time point.
The median (IQR) age of the cohort was `r .tbl1("Age")` years.

Most of the patients presented with cirrhosis
(`r .tbl1("Cirrhosis")`).
The remaining patients had an acute liver failure
(`r .tbl1("ALF")`) or
a chronic liver insufficiency
(`r .tbl1("CLI")`).
At evaluation time the median (IQR) MELD and MELD-Na score were
`r .tbl1("ScoreMeldUnos")` and
`r .tbl1("ScoreMeldNaUnos")`, respectively.
Within 90 days `r .tbl1("M90")` patients died.
In nearly two third of all patients alcohol was the main cause
(`r .tbl1("Ethyltoxic")`) of their end-stage liver disease.
The remaining patients had viral infections
(hepatitis B and C viruse `r .tbl1("HBV")` and `r .tbl1("HCV")`, respectively),
autoimmune processes (autoimmune hepatitis `r .tbl1("AIH")`,
primary sclerosing cirrhosis `r .tbl1("PSC")`),
primary biliary cirrhosis `r .tbl1("PBC")` or unknown causes
(non-alcoholic steatohepatitis `r .tbl1("NASH")` and
cryptogenic hepatitis `r .tbl1("Cryptogenic")`).
The most common complications among all patients were gastrointestinal
bleedings in `r .tbl1("GIB")` patients, followed by
hepatocellular carcinoma (HCC) in `r .tbl1("HCC")` and
spontaneous bacterial peritonitis (SBP) in `r .tbl1("SBP")` patients.
Just `r .tbl1("Dialysis")` patients required a renal dialysis.

## MELD scores

According to @wiesner2003 we divided our cohort into
`r nlevels(labelled_meld_data$MeldCategory)` MELD-score risk
categories, with `r enum(table(labelled_meld_data$MeldCategory))` patients,
respectively.
As shown in Table \@ref(tab:tbl-observed-vs-expected-mortality)
our observed 90 day mortality was
`r paste(round(range(tbl_observed_vs_expected_mortality$StandardizedMortalityRatio[-1]), 1), collapse = " to ")`
times higher than the predicted one. Just in the group with the lowest MELD
scores the mortality was much lower.

```{r tbl-observed-vs-expected-mortality, results = "asis", echo = FALSE, message = FALSE}
tbl_observed_vs_expected_mortality$ObservedMortality <-
    tbl_observed_vs_expected_mortality$ObservedMortality * 100
tbl_observed_vs_expected_mortality$ExpectedMortality <-
    tbl_observed_vs_expected_mortality$ExpectedMortality * 100
knitr::kable(
    cbind(
        row.names(tbl_observed_vs_expected_mortality),
        tbl_observed_vs_expected_mortality
    ),
    row.names = FALSE,
    col.names =
        c(
            "MELD category",
            "Observed deaths (n)",
            "Expected deaths (n)",
            "Standardized mortality ratio (SMR)",
            "Observed mortality (%)",
            "Expected mortality (%)"
        ),
    caption = paste0(
        "Observed vs MELD-expected 90 day mortality. ",
        "MELD mortality values are taken from @wiesner2003. ",
        "All patients censored before day 90 are ignored for ",
        " the calculation of the MELD-expected deaths. ",
        "SMR, Standardized mortality ratio = observed deaths/expected deaths."
    ),
    digits = 1
)
```

```{r benchmark-plot, fig.cap = "Benchmark results of machine learning algorithms.", echo = FALSE}
r <- bmrk_results$clone()
id <- grep("^scale", x = r$learners$learner_id, invert = TRUE, value = TRUE)
r$filter(task_id = "zlog_eldd", learner_id = id)
autoplot(r) +
    geom_boxplot(aes(fill = learner_id)) +
    geom_jitter(position = position_jitter(0.2)) +
    scale_fill_viridis(discrete = TRUE) +
    theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))
```

TODO: mention best ml algorithm (\@ref(fig:benchmark-plot))

# Discussion

In this retrospective analysis of `r n_analysed` consecutive patients,
who were recruited during the evaluation process for liver transplantation at
the University Hospital of Leipzig we developed a new model to predict the
90-day survival probability. Our new model outperforms the MELD-Na score and
the recently published MELD-Plus risk score.

**NUMBER_OF_VARIABLES**

- more variables, harder to cheat
- comparison of different predictors of MELD-Plus7 (+MELD-Plus9) vs our features

Sodium is not part of our model.
In line with the results presented in @kartoun2017 we could show that
adding sodium to MELD the discrimination performance increases just
insignificantly.

It has shown that women get lower scores in MELD-Na and therefore
are less likely getting an urgent listing for liver transplantation
[@Gaertner2022].
To address sexual differences in laboratory measurements we applied the *zlog*
transformation [@hoffmann2017].
Additionally this transformation yield comparable laboratory measurements
across different clinical laboratories and methods which could improve the
objectivity of the allocation process.
The already nearly normal scaled *zlog*-transformed laboratory measurements
allow us to avoid the sample depending scaling prior to model development.
Both should increase the external applicability of our approach.

Additionally to laboratory data we investigated
`r (ncol(raw_data) - length(cn_labs) - 2)`
clinical data but none of them were chosen in our model selection process.
@kartoun2017 used a similar penalizing approach and neither select any clinical
data. Especially in retrospective analysis the clinical data are often not
detailed enough.

In our benchmark of `r n_lrns` different machine learning algorithms we have
seen that the more complex algorithm like boosting and neural networks perform
worse than simpler ones.
This may due additive effects that favour regression models or due to our
relative small sample size.
In machine learning more than 200 events per predictor variable are necessary
to achieve good prediction performance [@ploeg2014].

<!--

- higher mortality than predicted, compare @hernaez2020
- adding sodium doesn't add much/any discrimination information
    - as already seen in @kartoun2017
- @kartoun2017 uses > 60 variables mostly clinical stuff, just few laboratory values, none of the clinical stuff remains
- general low sample size thus simpler models/fewer predictors are preferred.
- comparison of different predictors of MELD-Plus7 (+MELD-Plus9) vs our features
    - 90 day mortality *post* discharge
    - poorer performance in own validation set (lower and more uniform disease severity, also lower MELD)
- machine learning algorithms worse than statistical learning (lower c-index, higher variance/instability)
    - additive effects (favour statistical models)
    - low sample size, for ML more than 200 events per predictor variable necessary [@ploeg2014]
- sex-differences and sample-dependencies (by scaling) addressed by *zlog*.
- more variables, harder to cheat
- national register required
-->

## Limitations

Our study has limitations. Principally it is a single center, retrospective
analysis and without an external validation cohort.
The data were collected during the evaluation process for liver transplantation
at the University Hospital of Leipzig.
There was no controlled follow-up process. Instead the follow-up information
were recored at the next clinical admission.
Furthermore we excluded all patients who had already a liver transplantation
which could artificial lower the disease severity of the cohort.

With a median MELD score of `r .tbl1("ScoreMeldUnos")` our
cohort was healthier than in previous studies that reported
a score of 14-15 [@kim2008; @kartoun2017].
However the 90-day mortality rate of `r .tbl1("M90")` was comparable to
the mortality rates seen in earlier studies that ranges from 6 to 30%
[@malinchoc2000; @kim2008; @kartoun2017].
Although our cohort was healthier with a medium mortality rate the classical
MELD score underestimates the observed mortality
`r paste(round(range(tbl_observed_vs_expected_mortality$StandardizedMortalityRatio[-1]), 1), collapse = " to ")`
times.
Unfortunately our sample size is very low in the higher MELD categories which
yield a poor but better than MELD based prediction performance of our model
for very ill patients.

In conclusion we developed a new model to predict the 90-day survival of
patients during the evaluation process for liver transplantation.
Our model outperforms the established MELD-Na and the recently published
MELD-Plus risk scores.
For a wider adoption a prospective multi center study for model
recalibration and validation is needed.

<!--
Mortality
[@malinchoc2000] ~ 30 %
[@kim2008] ~ 6-7 %
[@kartoun2017] ~ 16.3 % (90 d, post-discharge-mortality)

random time point for blood sampling

It was not possible to ensure that patients died of end-stage liver disease.

The variables we found and the model itself have to be validated and
recalibrated in a multi center, prospective trial.

Few patients with high MELD scores, poor calibration for high mortality


- comparable mortality?
- retrospective analysis
- single center
- unknown cause of death (death with vs of end-stage liver disease)
- bias caused by LTx censorship?
-->

```{r co2e, include = FALSE}
tdp <- c(
    ## brain/(batch|login) Intel(R) Xeon(R) CPU E5-2650 v4 @ 2.20GHz
    ## https://ark.intel.com/content/www/us/en/ark/products/91767/intel-xeon-processor-e52650-v4-30m-cache-2-20-ghz.html
    login = 105,
    ## brain/snowball Intel(R) Xeon(R) Gold 6240 CPU @ 2.60GHz
    ## https://www.intel.com/content/www/us/en/products/sku/192443/intel-xeon-gold-6240-processor-24-75m-cache-2-60-ghz.html
    ## TDP 150, contains 2 processors
    ## (but even with workers = 72, we barely use more than 36, so 150 instead of 300 W should be fine)
    snowball = 150
)

## Umweltbundesamt
## Climate Change 45/2021 Entwicklung der spezifischen Kohlendioxid-Emissionen des deutschen Strommix in den Jahren 1990 - 2020
## Erscheinungsjahr Mai 2021, Autor(en): Petra Icha, Dr. Thomas Lauf, Gunter Kuhs
## p. 8
## https://www.umweltbundesamt.de/sites/default/files/medien/5750/publikationen/2021-05-26_cc-45-2021_strommix_2021_0.pdf
kgco2kwh <- 0.471

tm <- tar_meta(fields = c("name", "type", "seconds"))
tm <- tm[tm$type %in% c("pattern", "stem"),]
tm$node <-
    ifelse(grepl("^boot|^bmrks$|^arcvob$", tm$name), "snowball", "login")

tm$runtime <- tm$seconds *
    ifelse(tm$node == "snowball", 32, 1) # on snowball we use 32 workers
kgco2e <- sum((tm$runtime / 3600) * (tdp[tm$node] / 1000)) * kgco2kwh
kgco2e

## Umweltbundesamt
## √ñkologische Bewertung von Verkehrsarten
## Erscheinungsjahr August 2020, Autor(en): Michel Allekotte, Fabian Bergk, Kirsten Biemann, Carolin Deregowski, Wolfram Kn√∂rr, Hans-J√∂rg-Althaus, Daniel Sutter, Thomas Bergmann
## p. 214-215
## https://www.umweltbundesamt.de/sites/default/files/medien/479/publikationen/texte_156-2020_oekologische_bewertung_von_verkehrsarten_0.pdf
## Gesamt CO2eq (nur Verbrauch und Energiebereitstellung) je Personen km,
## A2, Tab. 69: PKW TTW 131 gCO2eq/Pkm, A3, Tab. 71.: PKW WTT 22 gCO2eq/Pkm
carkgco2e <- 153 / 1000
km <- kgco2e / carkgco2e
```

The calculations were conducted using the high performance computing (HPC)
cluster of the University Greifswald.
In 2018 the average carbon efficiency of the German power grid was
`r kgco2kwh` kgCO~2~eq/kWh [@icha2021].
A single run of the complete calculation pipeline took roughly
`r sprintf("%.1f", sum(tm$runtime) / 3600)` hours of computation on an
Intel(R) Xeon(R) E5-2650 v4 and
Intel(R) Xeon(R) Gold 6240 CPU (thermal design power: 105 and 150 W).
The total estimated emissions were at least
`r sprintf("%.2f", kgco2e)` kgCO~2~eq
(ignoring development, test runs, etc.).
This is equivalent to `r sprintf("%.1f", km)` km driven by an average car
[@allekotte2021].

# Acknowledgement

The study was supported by the AMPEL project (www.ampel.care).
This project is co-financed through public funds according to the budget
decided by the Saxon State Parliament under the
RL eHealthSax 2017/18 grant number 100331796.
The funder provided support in the form of
salaries for author SG
but did not have any additional role in the study design,
data collection and analysis, decision to publish, or preparation
of the manuscript.
We thank the whole AMPEL team for their support,
and Stefan Kemnitz for his technical support regarding the use of the
HPC cluster of the University Greifswald.

# References
