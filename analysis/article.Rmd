---
# R markdown template taken from
# Dan Holmes <dtholmes@mail.ubc.ca>
# https://labrtorian.com/2019/08/26/rmarkdown-template-that-manages-academic-affiliations/
title: "A new machine-learning based prediction of survival in patients with end-stage liver disease"
subtitle: >
    Comparision against MELD, MELD-Na, MELD-Plus7.
abstract: >
  **Objectives**:
      The shortage of grafts for liver transplantation requires
      risk stratification and adequate allocation rules.
      This study aims to improve the model of end-stage liver disease (MELD)
      score for 90-day mortality prediction with the help of different
      machine-learning algorithms.

  **Methods**:
      We retrospectively analyzed the clinical and laboratory data of 654
      patients who were recruited during the evaluation process for
      liver transplantation at University Hospital Leipzig.
      After comparing 13 different machine-learning algorithms in a nested
      cross-validation setting and selecting the best performing one we build
      a new model to predict 90-day mortality in patients with end-stage liver
      disease.

  **Results**:
      Penalized regression algorithms yielded the highest prediction
      performance in our machine-learning algorithm benchmark.
      In favor of a simpler model we chose the least absolute shrinkage and
      selection operator (lasso) regression.
      Beside the classical MELD variables international normalized ratio (INR)
      and bilirubin, the lasso regression selected cystatin C over creatinine,
      as well IL-6, total protein, and cholinesterase.
      The new model offers improved discrimination and calibration over MELD
      and MELD with sodium (MELD-Na) or the MELD-Plus7 risk score.

  **Conclusion**:
      We provide a new machine-learning-based model of end-stage liver disease
      that outperforms the classical MELD score for 90-day survival prediction.

  **Keywords**:
      end-stage liver disease; IL-6; machine learning; MELD;
      risk stratification; survival estimation

author:
    - Sebastian Gibb:
        email: mail@sebastiangibb.de
        institute: [ILM, KAINS]
        correspondence: true
    - Thomas Berg:
        email: thomas.berg@medizin.uni-leipzig.de
        institute: KIMH
        correspondence: false
    - Adam Herber:
        email: adam.herber@medizin.uni-leipzig.de
        institute: KIMH
        correspondence: false
    - Daniel Seehofer:
        email: daniel.seehofer@medizin.uni-leipzig.de
        institute: KVTTG
        correspondence: false
    - Berend Isermann:
        email: berend.isermann@medizin.uni-leipzig.de
        institute: ILM
        correspondence: false
    - Thorsten Kaiser:
        email: thorsten.kaiser@medizin.uni-leipzig.de
        institute: [ILM, ILMOWL]
        correspondence: false
institute:
    - ILM: Institute of Laboratory Medicine, Clinical Chemistry and Molecular Diagnostics, University Hospital Leipzig, Paul-List-Str. 13-15, D-04103 Leipzig, Germany.
    - KIMH: Section of Hepatology, Department of Gastroenterology and Rheumatology, University Hospital Leipzig, Liebigstr. 20, D-04103 Leipzig, Germany.
    - KVTTG: Department of Visceral, Transplantation, Vascular and Thoracic Surgery, University Hospital of Leipzig, Liebigstr. 20, D-04103 Leipzig, Germany.
    - KAINS: Anesthesiology and Intensive Care Medicine, University Hospital Greifswald, Ferdinand-Sauerbruch-Str., D-17475 Greifswald, Germany.
    - ILMOWL: Institute of Laboratory Medicine, Microbiology and Clinical Pathobiochemistry, University Hospital OWL, Hospital Lippe, Röntgenstr. 18, D-32756 Detmold, Germany.
date: "`r Sys.Date()`"
bibliography:
  - "`r rprojroot::find_rstudio_root_file('analysis', 'bibliography', 'bibliography.bib')`"
  - "`r rprojroot::find_rstudio_root_file('analysis', 'bibliography', 'rpackages', 'article.bib')`"
  - "`r rprojroot::find_rstudio_root_file('analysis', 'bibliography', 'rpackages', 'ameld.bib')`"
  - "`r rprojroot::find_rstudio_root_file('analysis', 'bibliography', 'rpackages', 'zlog.bib')`"
output:
  bookdown::html_document2:
    keep_md: true
    pandoc_args: # pandoc_args doesn't support r evaluation
      - --lua-filter=pandoc/lua-filters/scholarly-metadata.lua
      - --lua-filter=pandoc/lua-filters/author-info-blocks.lua
  bookdown::word_document2:
    keep_md: true
    pandoc_args: # pandoc_args doesn't support r evaluation
      - --lua-filter=pandoc/lua-filters/scholarly-metadata.lua
      - --lua-filter=pandoc/lua-filters/author-info-blocks.lua
      - --csl=pandoc/csl/vancouver.csl
---

```{r knitr_setup, include = FALSE}
knitr::write_bib(
    c(
        "base",
        "targets", "workflowr",
        "gtsummary",
        "mlr3", "mlr3proba",
        "survival", "glmnet", "penalized", "ranger", "randomForestSRC",
        "xgboost", "survivalsvm", "survivalmodels", "timeROC"
    ),
    file = rprojroot::find_rstudio_root_file(
        "analysis", "bibliography", "rpackages", "article.bib"
    )
)
cat(
    gsub("@Manual\\{", "@Manual\\{R-ameld", toBibtex(citation("ameld"))),
    file = rprojroot::find_rstudio_root_file(
        "analysis", "bibliography", "rpackages", "ameld.bib"
    )
)
cat(
    gsub("@Manual\\{", "@Manual\\{R-zlog", toBibtex(citation("zlog"))),
    file = rprojroot::find_rstudio_root_file(
        "analysis", "bibliography", "rpackages", "zlog.bib"
    )
)
```

```{r knitr_setup_word, eval = !knitr::is_html_output(), include = FALSE}
knitr::opts_chunk$set(dpi = 1200, dev = c("png", "pdf"))
```

```{r article_setup, include=FALSE}
library("targets")
library("ggplot2")
library("mlr3viz")
library("viridis")
library("ameld")
library("timeROC")

tar_load(bmrk_results)
tar_load(crossval)
tar_load(tuner)

tar_load(raw_data)
tar_load(labelled_meld_data)
tar_load(zlog_data)

tar_load(tbl1)
tar_load(tbl_observed_vs_expected_mortality)

tar_load(ameldcfg)
tar_load(amelddata)
tar_load(rngr)

tar_load(timeROC_MELD)
tar_load(timeROC_MELDNa)
tar_load(timeROC_MELDPlus7)
tar_load(timeROC_RCV)
```

# Introduction

Liver cirrhosis is the terminal result of the fibrotic remodeling
of liver tissue due to chronic damage.
This end-stage of liver disease is usually irreversible, and
the only available therapy is liver transplantation.
However, the shortage of grafts for transplantation from deceased donors
requires risk stratification and precise and fair allocation rules.
The allocation of liver transplantation in most countries is based on
disease severity determined by the model of end-stage liver disease (MELD)
[@malinchoc2000; @wiesner2003; @optn_policies2021].
The MELD score estimates patients' 3-month mortality risk based on
laboratory results, namely bilirubin, creatinine, and
the international normalized ratio (INR).
The MELD score has been extended by the sodium level
(MELD-Na score) because this was found to be an important additional
risk factor in liver cirrhosis [@kim2008; @optn_policies2021].
The MELD was initially developed to predict the survival of patients
undergoing transjugular intrahepatic portosystemic shunts.
It was subsequently revalidated to predict mortality risk in patients awaiting
a liver transplantation.
Although the MELD score should be an objective allocation score,
creatinine and INR are highly dependent on the laboratory methods used
[@trotter2004; @cholongitas2007].
In addition women are disadvantaged [@sealock2022].
Patients with identical disease states can have very different MELD scores and
thus receive different priority levels on the liver transplantation waiting
list.
Furthermore, for acute-on-chronic liver failure, for example, the MELD score
often underestimates the mortality risk [@hernaez2020].

There have been some attempts to use the data extracted from more than 300,000
electronic medical records from two hospitals in the United States to improve
the MELD score [@kartoun2017]. The derived MELD-Plus7 and MELD-Plus9
risk scores add albumin, white blood cell count, total cholesterol, age, and
length of stay to the MELD-Na variables.
Despite their published prediction improvement, the MELD-Plus scores are not
yet used for transplant allocation.

As shown by the MELD-Plus risk scores, better predictive scores often need more
variables and are more complicated. To reduce the risk of overlooking or
incorrectly calculating and interpreting the results,
clinical decision support systems may be used and could improve patient safety.
The research project on digital laboratory medicine (AMPEL) develops a
clinical decision support system based on laboratory diagnostics that should
support clinical practitioners in interpreting laboratory results and taking
the necessary medical interventions [@eckelt2020].

This study aims to find clinical and laboratory values that improve on the risk
stratification for liver transplantation of the classical MELD, MELD-Na, and
MELD-Plus scores and that might be implemented as part of the
AMPEL clinical decision support system.

# Material and methods

## Study population

```{r excluded, include = FALSE}
n_excluded <- attr(raw_data, "excluded")
n_analysed <- nrow(raw_data)
n_total <- sum(n_analysed, n_excluded)

cn_labs <- grep("_[CESQ]$", colnames(raw_data), value = TRUE)
```

In a retrospective cohort study we followed `r n_total` consecutive
patients, who were recruited during the evaluation process for
liver transplantation at University Hospital Leipzig from
`r paste(format(attr(raw_data, "period"), "%B %Y"), collapse = " to ")`.
For each patient, we recorded `r ncol(raw_data)` variables, including
age, sex, etiology of liver disease, complications as listed in
Table \@ref(tab:tbl1), and `r length(cn_labs)` laboratory measurements.

```{r flowchart, results = "asis", echo = FALSE, fig.width = 4.5, fig.height = 2, fig.cap = "Flowchart showing inclusion and exclusion of records."}
library("consort")
library("grid")

options(txt_gp = gpar(cex = 0.8))

total_records <- paste0("Total records (n = ", n_total, ")")
analysed_records <- paste0("Analyzed records (n = ", n_analysed, ")")
excluded_records <- paste0(
    "Excluded (n = ", sum(n_excluded), ")\n",
    paste0(
        "- ",
        c("Younger than 18 years",
          "Liver transplantation before visit",
          "Follow-up missing/invalid"
        ),
        " (n = ", n_excluded, ")",
        collapse = "\n"
    )
)

totalbox <- textbox(
    total_records,
    x = unit(0.25, "npc"), y = unit(0.9, "npc"),
    box_fn = rectGrob, name = "vertbox"
)
graph <- gList(gList(), totalbox)
class(graph) <- union("consort", class(graph))
graph <- structure(graph, split_layout = NULL)
graph <- add_side_box(graph, txt = excluded_records, dist = 0.1)
graph <- add_box(graph, txt = analysed_records, dist = 0.1)

#graph <-
#    add_box(txt = total_records) |>
#    add_side_box(txt = excluded_records, dist = 0.05) |>
#    add_box(txt = analysed_records, dist = 0.05) |>
plot(graph)
```

We excluded `r sum(n_excluded)` patients from our analysis
(Figure \@ref(fig:flowchart)).
`r if (n_excluded["Children"] == 1) "One was" else paste(n_excluded["Children"], "were")` younger than 18 years,
`r n_excluded["LiverTransplantation"]` had had a liver transplant before and
in `r n_excluded["LostFollowUp"]` cases the follow-up data were missing or
invalid.

The Ethics Committee at the Leipzig University Faculty of
Medicine approved the retrospective usage of the data for our study
(reference number: 039/14ff).

## MELD scores

MELD and MELD-Na were calculated as described in
@optn_policies2021 using the following formulas:
$MELD = 10 * (0.957 \ln(creatinine [mg/dL]) + 0.378 \ln(bilirubin [mg/dL]) + 1.120 * \ln(INR) + 0.643)$,
Creatinine, bilirubin and INR values lower than 1.0 mg/dL were set to 1.0 mg/dL.
The maximum allowed creatinine was 4.0 mg/dL. If the patients received dialysis,
creatinine was set to 4.0 mg/dL.
For MELD-Na, MELD was calculated as above and recalculated if greater than
11 using:
$MELD\text{-}Na = MELD_i + 1.32 * (137 - Na [mmol/L]) - (0.033 * MELD_i * (137 - Na [mmol/L]))$

Serum sodium values lower than 125 mmol/L or higher than 137 mmol/L were set
to 125 mmol/L and 137 mmol/L, respectively.

The MELD-Plus7 risk score was calculated as described in @kartoun2017:
$$
\begin{aligned}
L = 8.53499496 &+ \\
    2.59679650 &* \log_{10}(1 + creatinine [mg/dL]) + \\
    2.06503238 &* \log_{10}(1 + bilirubin [mg/dL]) + \\
    2.99724802 &* \log_{10}(1 + INR) - \\
    6.47834101 &* \log_{10}(1 + sodium [mmol/L]) - \\
    6.34990436 &* \log_{10}(1 + albumin [g/L]) + \\
    1.92811726 &* \log_{10}(1 + wbc [th/cumm]) + \\
    0.04070442 &* age [years]
\end{aligned}
$$

$$MELD\text{-}Plus = \frac{\exp(L)}{1 + \exp(L)}$$

The MELD-Plus9 score was ignored because the length of stay information was not
available for our cohort, and the model itself was not superior to MELD-Plus7
in its original publication [@kartoun2017].

## Data processing and machine learning

```{r ml, include = FALSE}
n_lrns <- sum(!grepl("^scale..*", bmrk_results$learners$learner_id))
```

All data processing, statistical, and machine-learning analyses were performed
using R version
`r paste0(sessionInfo()$R.version[c("major", "minor")], collapse = ".")`
[@R-base].
Prior to the analyses, all laboratory values were *zlog* transformed to
approximate a normal distribution as described in
@hoffmann2017 and implemented in @R-zlog.

$$
z = (\log(x) - \frac{\log(LL) + \log(UL)}{2}) * \frac{3.92}{\log(UL) - \log(LL)}
$$

where $LL$ and $UL$ are the lower and upper age-, and sex-related
reference limits of the corresponding laboratory diagnostic, respectively.
Missing laboratory measurements were replaced with a *zlog* value of zero.
In a similar manner, where information about complications or
comorbidities was missing, we treated them as not present.

We compared `r n_lrns` different statistical and machine-learning
algorithms using the *mlr3* framework
[@mlr3; @R-mlr3; @mlr3proba2021; @R-mlr3proba].
The algorithms used were designed for analysis of survival data:
Cox proportional hazards regression model
[@cox1972; @survival-book; @R-survival];
penalized regressions,
namely, two different implementations of the
lasso (least absolute shrinkage and selection operator) regression
[@tibshirani1997; @glmnet2011; @R-glmnet; @penalized2010; @R-penalized],
two different implementations of the
ridge regression [@glmnet2011; @R-glmnet; @penalized2010; @R-penalized], and
the elastic net regression [@glmnet2011; @R-glmnet];
two different random forest implementations
[@ranger2017; @R-ranger; @randomForestSRC2008; @R-randomForestSRC];
extreme gradient boosting [@chen2016; @R-xgboost];
two different support vector machines [@vanbelle2011; @R-survivalsvm];
;nd two neural networks [@katzman2018; @kvamme2019; @R-survivalmodels].

We used nested resampling to avoid feature- and
model-selection-bias to obtain reliable metrics to choose the best model.
We thus applied a `r crossval$inner$param_set$values$folds`-fold inner
and `r crossval$outer$param_set$values$folds`-fold outer cross-validation
that was repeated `r crossval$outer$param_set$values$repeats` times.
We searched the hyperparameter space using a grid search with a resolution of
`r tuner$param_set$get_values()$resolution`.
The models were evaluated using the concordance index, which is a measure of
rank correlation between predicted and observed events [@harrell1982].
Subsequently, we selected the model with the highest median concordance index.
If multiple models were comparable, we chose the simpler (more penalized) one.

After selecting the final model, we trained and validated it as described in
@harrell1996.
Briefly, we developed our model using a `r ameldcfg$nfold`-fold
cross-validation that was repeated `r ameldcfg$nrepcv` times and finally
predicted survival at `r ameldcfg$times` days.
The predictions were sorted and grouped into equal-sized intervals so that there
were `r ameldcfg$m` patients in each interval.
For each group, the mean survival probability and the difference to the
Kaplan-Meier estimate was calculated.
The same procedure was repeated for `r ameldcfg$nboot` bootstrap samples.
Subsequently, the differences between predicted survival and Kaplan-Meier
estimates of the bootstrap samples were averaged and added to the original
model difference to obtain a bias-corrected estimate between predicted and
observed survival.

The final model was compared against the MELD, MELD-Na, and MELD-Plus7 scores
using the area under the time-dependent receiver operating characteristic curve
(AUROC) based on the nonparametric inverse probability of censoring weighting
estimator (IPCW) [@blanche2013, @R-timeROC].
Testing was applied as described in @blanche2013.
A $p < 0.05$ was considered a statistically significant difference.

Summary tables were built using the *gtsummary* package
[@gtsummary; @R-gtsummary].

# Results

## Baseline characteristics

```{r tbl1, results = "asis", echo = FALSE, message = FALSE, warning = FALSE}
library("gtsummary")
theme_gtsummary_journal(journal = "jama")
theme_gtsummary_compact()
tbl1
```

```{r tbl1_helper_func, echo = FALSE}
.tbl1 <- function(variable, column = "Overall", ...) {
    id <- gtsummary::inline_text(
        tbl1, variable = all_of(variable), column = "tbl_id1"
    )
    if (column == "Overall")
        column <- "stat_0"
    gtsummary::inline_text(
        tbl1$tbls[[id]],
        variable = all_of(variable), column = all_of(column), ...
    )
}
```

In this study, we analyzed a cohort of `r n_analysed` patients evaluated for
liver transplantation (Tab. \@ref(tab:tbl1)).
Of these,
`r sprintf("%i (%s)", sum(raw_data$Sex == "male"), gtsummary::style_percent(mean(raw_data$Sex == "male"), symbol = TRUE))`
were men.
The median (IQR) follow-up times was `r .tbl1("DaysAtRisk")` days.
Within the follow-up time, `r .tbl1("LTx")` patients received a liver transplant
and were censored for the analysis beyond this time point.
The median (IQR) age of the cohort was `r .tbl1("Age")` years.

Most of the patients presented with cirrhosis
(`r .tbl1("Cirrhosis")`).
The remaining patients had acute liver failure
(`r .tbl1("ALF")`) or
chronic liver insufficiency
(`r .tbl1("CLI")`).
At evaluation time, the median (IQR) MELD and MELD-Na scores were
`r .tbl1("ScoreMeldUnos")` and
`r .tbl1("ScoreMeldNaUnos")`, respectively.
Within 90 days, `r .tbl1("M90")` patients had died.
In nearly two thirds of all patients
(`r .tbl1("Ethyltoxic")`), alcohol was the main cause
of their end-stage liver disease.
The remaining patients had viral infections -
hepatitis B (`r .tbl1("HBV")`) or C (`r .tbl1("HCV")`) -
autoimmune autoimmune (`r .tbl1("AIH")`),
primary sclerosing cirrhosis (`r .tbl1("PSC")`),
primary biliary cirrhosis (`r .tbl1("PBC")`), unknown causes
(non-alcoholic steatohepatitis (`r .tbl1("NASH")`), or
cryptogenic hepatitis (`r .tbl1("Cryptogenic")`)).
The most common complications among all patients were gastrointestinal
bleedings in `r .tbl1("GIB")` patients, followed by
hepatocellular carcinoma (HCC) in `r .tbl1("HCC")` and
spontaneous bacterial peritonitis (SBP) in `r .tbl1("SBP")` patients.
Just `r .tbl1("Dialysis")` patients required renal dialysis.

## MELD scores

According to @wiesner2003, we divided our cohort into
`r nlevels(labelled_meld_data$MeldCategory)` MELD-score risk
categories, with `r enum(table(labelled_meld_data$MeldCategory))` patients,
respectively.
As shown in Table \@ref(tab:tbl-observed-vs-expected-mortality),
our observed 90-day mortality was
`r paste(round(range(tbl_observed_vs_expected_mortality$StandardizedMortalityRatio[-1]), 1), collapse = " to ")`
times higher than the predicted one.
Only in the group with the lowest MELD scores was the mortality much lower.

```{r tbl-observed-vs-expected-mortality, results = "asis", echo = FALSE, message = FALSE}
tbl_observed_vs_expected_mortality$ObservedMortality <-
    tbl_observed_vs_expected_mortality$ObservedMortality * 100
tbl_observed_vs_expected_mortality$ExpectedMortality <-
    tbl_observed_vs_expected_mortality$ExpectedMortality * 100
knitr::kable(
    cbind(
        row.names(tbl_observed_vs_expected_mortality),
        tbl_observed_vs_expected_mortality
    ),
    row.names = FALSE,
    col.names =
        c(
            "MELD category",
            "Observed deaths (n)",
            "Expected deaths (n)",
            "Standardized mortality ratio (SMR)",
            "Observed mortality (%)",
            "Expected mortality (%)"
        ),
    caption = paste0(
        "Observed vs. MELD-expected 90-day mortality. ",
        "MELD mortality values are taken from @wiesner2003. ",
        "All patients censored before day 90 are ignored for ",
        " the calculation of the MELD-expected deaths. ",
        "SMR, Standardized mortality ratio = observed deaths/expected deaths."
    ),
    digits = 1
)
```

## AMPEL MELD

The penalized regression and random forest models
resulted in a similar high median performance in the benchmark process.
In favour of simpler models, we chose a lasso-based approach for the final model
development.
The classical Cox model, the data and computational intense algorithms
extreme gradient boosting, the support vector machines and the neural networks
yielded a worse performance.

```{r coeftbl, echo = FALSE}
tar_load(bootrcv)
cf <- coef(bootrcv$fit)
cf <- setNames(cf@x, rownames(cf)[cf@i + 1])
o <- order(-abs(cf))
cfs <- cf[o]
cfnms <- lapply(
    labelled_meld_data[names(cfs)],
    function(nm)sub(" *\\[.*$", "", attr(nm, "label"))
)
cfnms[!lengths(cfnms)] <- names(cfnms)[!lengths(cfnms)]
knitr::kable(
    setNames(cfs, cfnms),
    col.names = "Coefficient",
    caption = "Model coefficients",
    digits = 3
)
```

The resulting AMPEL model of end-stage liver disease
(AMELD) uses `r length(cfs)` predictors.
Besides the classical MELD variables INR and (direct) bilirubin,
the lasso regression selected cystatin C over creatinine, as well as
IL-6, total protein, and cholinesterase.

```{r basehaz, echo = FALSE}
bh <- basehaz(
    bootrcv$fit, x = amelddata$x, y = amelddata$y, s = "lambda.1se",
    times = timeROC_RCV$times, centered = FALSE
)
s0 <- setNames(1 - bh$hazard, bh$time)
k <- knitr::kable(
    t(s0),
    digits = 4,
    caption = paste0(
        "Underlying survival function; S~0~: baseline survival estimate"
    )
)
k[3] <- paste("|t [days]", k[3])
k[4] <- paste0("|:------", k[4])
k[5] <- paste("|S~0~ (t)", k[5])
k
```

The 90-day survival estimate of a given patient can be calculated as shown in
\@ref(eq:survcalc).

```{r survivalcalc, results = "asis", echo = FALSE}
cfnmsltx <- paste0("\\text{", gsub(" ", "\\ ", cfnms), "}")
cat(
    "$$\\begin{align}",
    "S &= S_{0,90}^{\\exp{LP}} \\\\",
    "&= ", round(s0["90"], 4), "^{\\exp{(",
        paste0(
            round(cfs[1], 4), " * zlog(", cfnmsltx[1], ")",
            paste0(
                ifelse(sign(cfs[-1]) > 0, "+", ""),
                round(cfs[-1], 4), " * zlog(", cfnmsltx[-1], ")",
                collapse = ""
            ),
            collapse = ""
        ),
    ")}}"
)
```
(\#eq:survcalc)
\end{align}
$$
<!-- using eq:survcalc inside the R code chunk impedes Math ML rendering -->

where $S_{0}$ is the baseline survival estimate from
\@ref(tab:basehaz) and $LP$ is the linear predictor of the coefficients
in \@ref(tab:coeftbl).

## Model comparison

```{r roc, fig.width = 7, fig.height = 7, echo = FALSE, message = FALSE, fig.cap = "Receiver operating characteristic (ROC) curve. Area under the time-dependent ROC curve (AUC) based on the nonparametric inverse probability of censoring weighting estimate (IPCW) for AMELD, MELD, MELD-Na, and MELD-Plus7, as described in [@blanche2013]."}
col <- viridisLite::viridis(5)
m <- list(
    AMELD = timeROC_RCV,
    MELD = timeROC_MELD,
    "MELD-Na" = timeROC_MELDNa,
    "MELD-Plus7" = timeROC_MELDPlus7
)
invisible(roc <- plot_surv_roc(m, timepoint = 90, col = col[-2]))
roc <- roc[order(-roc)]
```

```{r roctest, echo = FALSE}
tp <- timeROC::compare(
    timeROC_RCV, timeROC_MELDNa,
    adjusted = TRUE
)$p_values_AUC
rownames(tp) <- paste(
    c("Non-adjusted", "Adjusted"), "$p$-values"
)
knitr::kable(
    tp,
    caption = paste0(
        "Test comparison between AUCROC for MELD-Na and AMELD ",
        "according to @blanche2013 at day ",
        paste0(timeROC_RCV$times, collapse = ", "), ".",
        "$p$-values are shown as non-adjusted and adjusted for ",
        "multiple testing."
    ),
    digits = 2
)
```

AMELD offers the best AUROC (`r round(roc["AMELD"], 3)`) of all competitors.
However, after correction for multiple testing, the difference against
the second-best model, `r names(roc)[2]`
(AUROC: `r round(roc[2], 3)`), is not statistical significant
(`r paste0("$p = ", round(tp[2, "t=90"], 2), "$")`)
(see Table \@ref(tab:roctest) for complete comparison).

```{r bootrcv, echo = FALSE, fig.width = 8, fig.height = 6, fig.cap = paste('Calibration of AMELD in comparison to MELD, MELD-Na, and MELD-Plus7.\n The points mark the mean predicted survival of', ameldcfg$m, 'patients per interval against their observed mean survival. The error bars correspond to the 95% confidence interval of the survival estimate.'), echo = FALSE}
par(cex = 0.9)
plot(
    bootrcv,
    what = "calibration",
    main = "90-day survival",
    legend = FALSE
)

ps <- lapply(
    zlog_data[paste0("SurvProbMeld", c("Unos", "NaUnos", "Plus7"))],
    function(p) {
        ctpnts <- cutpoints(p, n = ameldcfg$m)
        f <- cut(p, ctpnts, include.lowest = TRUE)
        list(
            predicted = groupmean(p, f = f),
            observed = observed_survival(
                amelddata$y, f = f, times = ameldcfg$times
            )
        )
    }
)
names(ps) <- c("MELD", "MELD-Na", "MELD-Plus7")

for (i in seq_along(ps)) {
    lines(
        ps[[i]]$predicted, ps[[i]]$observed, col = col[i + 2],
        type = "b", pch = 19
    )
}
legend(
    "topleft",
    col = col,
    legend = c(
        "AMELD",
        paste0(
            "AMELD, optimism error added (based on ",
            length(bootrcv$models),
            " bootstrap samples)"
        ),
        names(ps)
    ),
    pch = c(19, 4, rep(19, 3)),
    bty = "n"
)
```

Fig. \@ref(fig:bootrcv) depicts the calibration curve for AMELD and the
competing MELD scores.
While the prediction for low-risk patients is similar to other scores,
AMELD predicts the medium-risk patients more accurately.

# Discussion

In this retrospective analysis of `r n_analysed` consecutive patients
who were recruited during the evaluation process for liver transplantation at
University Hospital Leipzig, we developed a new model to predict
90-day survival probability. Our new model, AMELD, outperforms the MELD-Na
score and the recently published MELD-Plus7 risk score.

```{r selvar, echo = FALSE}
bsrank <- as.vector(rank(-ameld:::.selvars(bootrcv$models, bootrcv$s), ties = "first")["NA_S"])

bsranktxt <-
    if (!is.na(bsrank)) {
        paste0("in bootstrap selection rank ", bsrank, " of ", ncol(amelddata$x))
    } else {
        paste0("it was never selected in any boostrap sample")
    }

rfrank <- as.vector(rank(-rngr$variable.importance, ties = "first")["NA_S"])
rfranktxt <-
    paste0("in a random forest variable importance rank ", rfrank, " of ", ncol(amelddata$x))
```

Although the Organ Procurement and Transplantation Network recommends the use
of MELD-Na over MELD, the sodium does not add any information to the score.
Neither in the bootstrap selection nor in the variable importance of a
random forest model does the sodium gain any important weight
(`r bsranktxt` and `r rfranktxt`, see \@ref(fig:vimpbs), \@ref(fig:vimprf)).
In addition, sodium levels can be affected by diuretic therapy, and
the discrimination performance of MELD-Na has already been shown by
@kartoun2017 to be insignificantly different from the classical MELD.
Consequently it is not a component of our model.

It has been shown that women receive median lower scores in MELD-Na and
therefore are less likely to receive an urgent listing for liver transplantation
[@sealock2022].
To address sexual differences, in laboratory measurements we applied the *zlog*
transformation [@hoffmann2017] in our study.
This transformation also yields comparable laboratory measurements
across different clinical laboratories and methods, as well as reducing
the influence of age- and sex-related differences,
which could improve the objectivity of the allocation process.
The already nearly normal scaled *zlog*-transformed laboratory measurements
allow us to avoid the sample-dependent scaling prior to model development.
Both should increase the external applicability of our approach.

Our model, AMELD, uses `r length(cfs)` predictors.
Three of these - INR, (direct) bilirubin, and cystatin C - are identical
or similar to the laboratory measurements utilized in the classical MELD.
The direct bilirubin selected by our approach and the total bilirubin in MELD
are highly correlated (Spearman correlation:
`r round(cor(amelddata$x, method = "spearman")["BILI_S", "BILID_S"], 2)`) and
therefore interchangeable.

In our feature selection process, cystatin C was chosen instead of creatinine.
This is in line with recent studies that show a better prediction of mortality
for cystatin C in unselected and critically ill patients
[@helmerssonkarlqvist2016; @helmerssonkarlqvist2021].

Furthermore AMELD, extends MELD by the additional synthesis parameters
total protein and cholinesterase, and
most importantly the inflammatory marker IL-6.

The latter is an example where results from machine-learning can aid in
finding clinically meaningful patterns and guide further research.
Systemic inflammatory response syndrome is an
independent risk factor for poor outcomes in patients with cirrhosis
[@thabut2007].
However, neither MELD nor MELD-Na took inflammation into account.
By contrast, IL-6 is the most important variable in our model. Even if IL-6 is
excluded, the algorithms select CRP as one of the most important variables,
which highlights the important role of inflammation in the prognosis of
patients with end-stage liver disease.
We and other researchers have already shown that adding inflammatory markers,
namely IL-6 or CRP, to the classical MELD score increases the accuracy of the
90-day mortality prediction [@remmler2018; @cervoni2016].

Besides laboratory measurements, we investigated
`r (ncol(raw_data) - length(cn_labs) - 2)` other items of
clinical data, but none were chosen in our model-selection process.
@kartoun2017 also used the lasso approach and did not select any clinical
data.
In retrospective analyses in particular, the clinical data are often not
detailed enough to provide valuable information.

In our benchmark of `r n_lrns` different machine-learning algorithms we have
seen that the more complex algorithms, such as boosting,
support vector machines, and neural networks, perform worse than simpler ones.
This may be due to additive effects that favor regression models or due to our
relatively small sample size.
It has been shown that in machine-learning more than 200 events per
predictor variable are required to achieve good prediction performance
[@ploeg2014].

## Limitations

Our study has several limitations.
Principally, it is a single-center, retrospective analysis lacking an
external validation cohort.
The data were collected during the evaluation process for liver transplantation
at University Hospital Leipzig.
There was no controlled follow-up process.
We excluded all patients who had already undergone liver transplantation,
which could artificially lower the disease severity of the cohort.
Furthermore, most of our patients suffered from ethyltoxic liver cirrhosis
(`r .tbl1("Ethyltoxic", pattern = "{p}%")`), which may
limited the transfer to other etiologies.

With a median MELD score of `r .tbl1("ScoreMeldUnos", pattern = "{median}")`,
our cohort was healthier than those in previous studies that reported
a score of 14-15 [@kim2008; @kartoun2017].
However, the 90-day mortality rate of `r .tbl1("M90")` was comparable to
the mortality rates seen in earlier studies ranging from 6% to 30%
[@malinchoc2000; @kim2008; @kartoun2017].
Although our cohort was healthier, with a medium mortality rate, the classical
MELD score underestimates the observed mortality by
`r paste(round(range(tbl_observed_vs_expected_mortality$StandardizedMortalityRatio[-1]), 1), collapse = " to ")`
times.
Unfortunately, our sample size was low in the high-risk patient category,
resulting in a poor but better than MELD-based prediction performance by our
AMELD for very ill patients.

# Conclusion

In conclusion, we have developed a new model to predict the 90-day survival of
patients during the evaluation process for liver transplantation.
Our model, AMELD, extends the classical MELD predictors INR,
(direct) bilirubin, and cystatin C (instead of creatinine) by using the
synthesis parameters total protein and cholinesterase and,
most importantly, the inflammatory marker IL-6.
Using these six laboratory measurements, AMELD
outperforms the established MELD-Na and the recently published
MELD-Plus7 risk scores.
For wider adoption, a prospective multi-center study for model
recalibration and validation is needed.

## Acknowledgments

We thank the whole AMPEL team for their support,
Stefan Kemnitz for his technical support regarding the use of the
high-performance computing (HPC) cluster at the University of Greifswald and
Bernd Klaus for helpful discussions about survival analysis and
proofreading the manuscript.


```{r co2e, include = FALSE}
tdp <- c(
    ## brain/(batch|login) Intel(R) Xeon(R) CPU E5-2650 v4 @ 2.20GHz
    ## https://ark.intel.com/content/www/us/en/ark/products/91767/intel-xeon-processor-e52650-v4-30m-cache-2-20-ghz.html
    login = 105,
    ## brain/snowball Intel(R) Xeon(R) Gold 6240 CPU @ 2.60GHz
    ## https://www.intel.com/content/www/us/en/products/sku/192443/intel-xeon-gold-6240-processor-24-75m-cache-2-60-ghz.html
    ## TDP 150, contains 2 processors
    ## (but even with workers = 72, we barely use more than 36, so 150 instead of 300 W should be fine)
    snowball = 150
)

## Umweltbundesamt
## Climate Change 45/2021 Entwicklung der spezifischen Kohlendioxid-Emissionen des deutschen Strommix in den Jahren 1990 - 2020
## Erscheinungsjahr Mai 2021, Autor(en): Petra Icha, Dr. Thomas Lauf, Gunter Kuhs
## p. 8
## https://www.umweltbundesamt.de/sites/default/files/medien/5750/publikationen/2021-05-26_cc-45-2021_strommix_2021_0.pdf
kgco2kwh <- 0.471

tm <- tar_meta(fields = c("name", "type", "seconds"))
tm <- tm[tm$type %in% c("pattern", "stem"),]
tm$node <-
    ifelse(grepl("^boot|^bmrks$|^arcvob$", tm$name), "snowball", "login")

tm$runtime <- tm$seconds *
    ifelse(tm$node == "snowball", 32, 1) # on snowball we use 32 workers
kgco2e <- sum((tm$runtime / 3600) * (tdp[tm$node] / 1000)) * kgco2kwh
kgco2e

## Umweltbundesamt
## Ökologische Bewertung von Verkehrsarten
## Erscheinungsjahr August 2020, Autor(en): Michel Allekotte, Fabian Bergk, Kirsten Biemann, Carolin Deregowski, Wolfram Knörr, Hans-Jörg-Althaus, Daniel Sutter, Thomas Bergmann
## p. 214-215
## https://www.umweltbundesamt.de/sites/default/files/medien/479/publikationen/texte_156-2020_oekologische_bewertung_von_verkehrsarten_0.pdf
## Gesamt CO2eq (nur Verbrauch und Energiebereitstellung) je Personen km,
## A2, Tab. 69: PKW TTW 131 gCO2eq/Pkm, A3, Tab. 71.: PKW WTT 22 gCO2eq/Pkm
carkgco2e <- 153 / 1000
km <- kgco2e / carkgco2e
```

The calculations were conducted using the HPC cluster at
University of Greifswald.
In 2018, the average carbon efficiency of the German power grid was
`r kgco2kwh` kgCO~2~eq/kWh [@icha2021].
A single run of the complete calculation pipeline took roughly
`r round(sum(tm$runtime) / 3600)` hours of computation on an
Intel(R) Xeon(R) E5-2650 v4 and
Intel(R) Xeon(R) Gold 6240 CPU (thermal design power: 105 and 150 W).
The total estimated emissions were at least
`r sprintf("%.2f", kgco2e)` kgCO~2~eq
(ignoring development, test runs, etc.).
This is equivalent to `r round(km)` km driven by an average car
[@allekotte2021].

## Research funding

The study was supported by the AMPEL project ([www.ampel.care](https://www.ampel.care)).
This project is co-financed through public funds according to the budget
decided by the Saxon State Parliament under
RL eHealthSax 2017/18 grant number 100331796.
The funder provided support in the form of
salaries for author SG
but did not have any additional role in the study design,
data collection and analysis, decision to publish, or preparation
of the manuscript.

## Author contributions

Funding was acquired by TK.
The study was conceptualized by SG and TK.
The data were acquired by TK.
The data were analyzed and processed by SG.
Visualization was produced by SG.
The original drafts of the manuscript were written by SG and TK.
Drafts were edited and reviewed by SG, TB, AH, DS, BI, and TK.
The project was supervised by TK.
All authors have accepted responsibility for the entire content of this
manuscript and have approved its submission.

## Competing interests

TB recieved grants or research support from
Abbvie, BMS, Gilead, MSD/Merck, Humedics, Intercept, Merz, Norgine, Novartis, Orphalan, Sequana Medical.
TB received honoraria or consultation fees/advisory board from
Abbvie, Alexion, Bayer, Gilead, GSK, Eisai, Enyo Pharma, Falk Foundation, HepaRegeniX GmbH, Humedics,  Intercept, Ipsen, Janssen, MSD/Merck, Novartis, Orphalan, Roche,
Sequana Medical, SIRTEX, SOBI, and Shionogi
TB participated in a company sponsored speaker’s bureau for
Abbvie, Alexion, Bayer, Gilead, Eisai, Intercept, Ipsen, Janssen, MedUpdate GmbH, MSD/Merck, Novartis, Orphalan, Sequana Medica, SIRTEX, and SOBI.
All other authors state no conflict of interest.

## Informed consent

Informed consent was obtained from all individuals included in this study.

## Ethical approval

Research involving human subjects complied with all relevant national
regulations and institutional policies, as well as the tenets of
the Helsinki Declaration (as revised in 2013), and was
approved by the Ethics Committee at the Leipzig University Faculty of
Medicine (reference number: 039/14ff).

## Data and software availability

The complete code and reproducible analysis can be found at
https://ampel-leipzig.github.io/ampel-leipzig-meld/.
In addition, all data are available in the `ameld` R package [@R-ameld] at
https://github.com/ampel-leipzig/ameld
[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.6666018.svg)](https://doi.org/10.5281/zenodo.6666018)
for further investigation.

# References
